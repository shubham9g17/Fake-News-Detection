Web Scrapers for various websites

Dependencies:
* Anaconda Distribution for Python
* Scrapy
```pip install scrapy```
* Scrapy-Selenium
```pip install scrapy-selenium```
* PRAW
```pip intall praw```
* Selenium
```pip install selenium```
* Pdfkit (For saving Webpages as pdf)
```pip install pdfkit```
* Spotipy
```pip install spotipy```


* [AltNews](https://www.altnews.in) ```Crawler```
  
      scrapy crawl education
      scrapy crawl news
      scrapy crawl politics
      scrapy crawl religion
      scrapy crawl science
      scrapy crawl society




* [Inshorts](https://inshorts.com/en/read) ```Crawler```

      scrapy crawl automobile
      scrapy crawl business
      scrapy crawl entertainment
      scrapy crawl hatke
      scrapy crawl home
      scrapy crawl miscellaneous
      scrapy crawl national
      scrapy crawl politics
      scrapy crawl science
      scrapy crawl sports
      scrapy crawl sports
      scrapy crawl startup
      scrapy crawl technology
      scrapy crawl world

Instructions:
* Crawlers:
      Traverse to the directory in the command line and type
```scrapy crawl <crawler name> -o <outfilename>```
* Notebooks:
      Just run them in any jupyter environment
* Automated Browser:
    Make sure you have got chrome driver installed from [here](https://sites.google.com/a/chromium.org/chromedriver/downloads) before running the notebook
